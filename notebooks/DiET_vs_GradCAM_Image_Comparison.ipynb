{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî¨ DiET vs GradCAM: Discriminative Feature Attribution for Image Classification\n",
    "\n",
    "## A Comprehensive Comparison Study\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** Machine Learning Research Team  \n",
    "**Date:** 2025-2026 Academic Year  \n",
    "**Course:** Advanced Machine Learning\n",
    "\n",
    "---\n",
    "\n",
    "### üìã Abstract\n",
    "\n",
    "This notebook presents a comprehensive experimental comparison between **DiET (Distractor Erasure Tuning)** and **GradCAM** for explainable AI in image classification tasks. We evaluate both methods on multiple image datasets (CIFAR-10, CIFAR-100, SVHN, Fashion-MNIST) using robust evaluation metrics including pixel perturbation, AOPC, and faithfulness correlation.\n",
    "\n",
    "### üéØ Research Questions\n",
    "\n",
    "1. Does DiET produce more discriminative feature attributions than GradCAM?\n",
    "2. How do both methods perform across different image classification datasets?\n",
    "3. What is the trade-off between model accuracy and attribution quality?\n",
    "\n",
    "### üìö Reference\n",
    "\n",
    "Bhalla, U., et al. (2023). **\"Discriminative Feature Attributions: Bridging Post Hoc Explainability and Inherent Interpretability.\"** *NeurIPS 2023.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "### 1.1 Check GPU Availability\n",
    "\n",
    "This notebook is optimized for **Google Colab Pro** with GPU acceleration. We recommend using a T4 or A100 GPU for faster training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability and type\n",
    "import torch\n",
    "import subprocess\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üñ•Ô∏è  HARDWARE CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "    print(f\"‚úÖ GPU Available: {gpu_name}\")\n",
    "    print(f\"   Memory: {gpu_memory:.1f} GB\")\n",
    "    \n",
    "    # Check CUDA version\n",
    "    print(f\"   CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"   PyTorch Version: {torch.__version__}\")\n",
    "    \n",
    "    if gpu_memory >= 15:\n",
    "        print(\"\\nüöÄ High-memory GPU detected! Using optimal settings.\")\n",
    "        GPU_CONFIG = \"high\"\n",
    "    elif gpu_memory >= 8:\n",
    "        print(\"\\n‚ú® Standard GPU detected. Using balanced settings.\")\n",
    "        GPU_CONFIG = \"standard\"\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  Low-memory GPU detected. Using memory-efficient settings.\")\n",
    "        GPU_CONFIG = \"low\"\n",
    "else:\n",
    "    print(\"‚ùå No GPU available. Training will be slow.\")\n",
    "    print(\"   Please enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
    "    GPU_CONFIG = \"cpu\"\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"\\nüìç Using device: {DEVICE.upper()}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Clone Repository and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "import os\n",
    "\n",
    "REPO_URL = \"https://github.com/xMOROx/Machine-Learning-Project-2025-2026.git\"\n",
    "REPO_DIR = \"Machine-Learning-Project-2025-2026\"\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    print(\"üì• Cloning repository...\")\n",
    "    !git clone --recursive {REPO_URL}\n",
    "    print(\"‚úÖ Repository cloned successfully!\")\n",
    "else:\n",
    "    print(\"üìÅ Repository already exists. Pulling latest changes...\")\n",
    "    %cd {REPO_DIR}\n",
    "    !git pull\n",
    "    !git submodule update --init --recursive\n",
    "    %cd ..\n",
    "\n",
    "%cd {REPO_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "print(\"üì¶ Installing dependencies...\")\n",
    "print(\"This may take a few minutes on first run.\\n\")\n",
    "\n",
    "!pip install -q torch torchvision --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q transformers datasets tqdm matplotlib seaborn pandas numpy pillow scikit-learn captum\n",
    "\n",
    "print(\"\\n‚úÖ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project to path and import modules\n",
    "import sys\n",
    "sys.path.insert(0, './scripts/xai_experiments')\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All modules imported successfully!\")\n",
    "print(f\"üìÖ Experiment started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Experimental Configuration\n",
    "\n",
    "### 2.1 Hyperparameters and Settings\n",
    "\n",
    "We configure the experiment based on available GPU memory to optimize training speed while maintaining result quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration based on GPU capabilities\n",
    "if GPU_CONFIG == \"high\":  # A100, V100, etc.\n",
    "    CONFIG = {\n",
    "        \"batch_size\": 128,\n",
    "        \"epochs\": 10,\n",
    "        \"max_samples\": 10000,\n",
    "        \"comparison_samples\": 200,\n",
    "        \"datasets\": [\"cifar10\", \"cifar100\", \"svhn\", \"fashion_mnist\"],\n",
    "    }\n",
    "elif GPU_CONFIG == \"standard\":  # T4, P100\n",
    "    CONFIG = {\n",
    "        \"batch_size\": 64,\n",
    "        \"epochs\": 5,\n",
    "        \"max_samples\": 5000,\n",
    "        \"comparison_samples\": 100,\n",
    "        \"datasets\": [\"cifar10\", \"cifar100\", \"svhn\", \"fashion_mnist\"],\n",
    "    }\n",
    "elif GPU_CONFIG == \"low\":  # K80, older GPUs\n",
    "    CONFIG = {\n",
    "        \"batch_size\": 32,\n",
    "        \"epochs\": 3,\n",
    "        \"max_samples\": 2000,\n",
    "        \"comparison_samples\": 50,\n",
    "        \"datasets\": [\"cifar10\", \"svhn\"],  # Fewer datasets for speed\n",
    "    }\n",
    "else:  # CPU\n",
    "    CONFIG = {\n",
    "        \"batch_size\": 16,\n",
    "        \"epochs\": 2,\n",
    "        \"max_samples\": 1000,\n",
    "        \"comparison_samples\": 20,\n",
    "        \"datasets\": [\"cifar10\"],  # Single dataset for demo\n",
    "    }\n",
    "\n",
    "# Display configuration\n",
    "print(\"=\" * 60)\n",
    "print(\"‚öôÔ∏è  EXPERIMENT CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Dataset Overview\n",
    "\n",
    "We evaluate on the following image classification datasets:\n",
    "\n",
    "| Dataset | Images | Classes | Image Size | Description |\n",
    "|---------|--------|---------|------------|-------------|\n",
    "| **CIFAR-10** | 60,000 | 10 | 32√ó32 | Natural images |\n",
    "| **CIFAR-100** | 60,000 | 100 | 32√ó32 | Fine-grained |\n",
    "| **SVHN** | 73,257 | 10 | 32√ó32 | Street numbers |\n",
    "| **Fashion-MNIST** | 70,000 | 10 | 28√ó28 | Fashion products |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images from datasets\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def show_dataset_samples(dataset_name, num_samples=8):\n",
    "    \"\"\"Display sample images from a dataset.\"\"\"\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "    if dataset_name == \"cifar10\":\n",
    "        dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "        classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    elif dataset_name == \"cifar100\":\n",
    "        dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
    "        classes = None  # Too many to display\n",
    "    elif dataset_name == \"svhn\":\n",
    "        dataset = torchvision.datasets.SVHN(root='./data', split='train', download=True, transform=transform)\n",
    "        classes = [str(i) for i in range(10)]\n",
    "    elif dataset_name == \"fashion_mnist\":\n",
    "        dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "        classes = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Boot']\n",
    "    \n",
    "    fig, axes = plt.subplots(1, num_samples, figsize=(16, 2))\n",
    "    for i in range(num_samples):\n",
    "        img, label = dataset[i]\n",
    "        axes[i].imshow(img.permute(1, 2, 0).numpy() if img.shape[0] == 3 else img.squeeze().numpy(), cmap='gray' if img.shape[0] == 1 else None)\n",
    "        if classes:\n",
    "            axes[i].set_title(classes[label], fontsize=10)\n",
    "        else:\n",
    "            axes[i].set_title(f\"Class {label}\", fontsize=10)\n",
    "        axes[i].axis('off')\n",
    "    plt.suptitle(f\"{dataset_name.upper()} Sample Images\", fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"üìä Dataset Samples Preview\")\n",
    "print(\"=\" * 60)\n",
    "for dataset in CONFIG[\"datasets\"]:\n",
    "    show_dataset_samples(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. DiET vs GradCAM Comparison Framework\n",
    "\n",
    "### 3.1 Method Overview\n",
    "\n",
    "#### GradCAM (Gradient-weighted Class Activation Mapping)\n",
    "- **Type:** Post-hoc explanation method\n",
    "- **Approach:** Uses gradients flowing into the final convolutional layer\n",
    "- **Limitation:** May highlight regions that are correlated but not discriminative\n",
    "\n",
    "#### DiET (Distractor Erasure Tuning)\n",
    "- **Type:** Inherent interpretability via fine-tuning\n",
    "- **Approach:** Learns masks that preserve model predictions while being sparse\n",
    "- **Advantage:** Produces truly discriminative attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the comparison framework\n",
    "from experiments.xai_comparison import XAIMethodsComparison, ComparisonConfig\n",
    "\n",
    "# Create configuration\n",
    "comparison_config = ComparisonConfig(\n",
    "    device=DEVICE,\n",
    "    image_datasets=CONFIG[\"datasets\"],\n",
    "    image_batch_size=CONFIG[\"batch_size\"],\n",
    "    image_epochs=CONFIG[\"epochs\"],\n",
    "    image_max_samples=CONFIG[\"max_samples\"],\n",
    "    image_comparison_samples=CONFIG[\"comparison_samples\"],\n",
    "    output_dir=\"./outputs/colab_experiments/image_comparison\",\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Comparison framework initialized!\")\n",
    "print(f\"üìÅ Output directory: {comparison_config.output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Run Experiments\n",
    "\n",
    "‚è±Ô∏è **Estimated Time:** \n",
    "- High-memory GPU: ~30-45 minutes\n",
    "- Standard GPU: ~20-30 minutes\n",
    "- Low-memory GPU: ~15-20 minutes\n",
    "- CPU: ~60+ minutes (not recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize comparison\n",
    "comparison = XAIMethodsComparison(comparison_config)\n",
    "\n",
    "# Run full comparison (images only)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üöÄ STARTING DiET vs GradCAM COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nüìä Datasets: {CONFIG['datasets']}\")\n",
    "print(f\"üî¢ Samples per dataset: {CONFIG['max_samples']}\")\n",
    "print(f\"üìà Training epochs: {CONFIG['epochs']}\")\n",
    "print(f\"\\n‚è≥ This may take a while. Progress will be shown below...\\n\")\n",
    "\n",
    "start_time = datetime.now()\n",
    "results = comparison.run_full_comparison(run_images=True, run_text=False)\n",
    "end_time = datetime.now()\n",
    "\n",
    "print(f\"\\n‚úÖ Experiment completed in {(end_time - start_time).seconds // 60} minutes {(end_time - start_time).seconds % 60} seconds!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Results Analysis\n",
    "\n",
    "### 4.1 Quantitative Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get results as DataFrame\n",
    "df = comparison.get_results_dataframe()\n",
    "\n",
    "# Display results table\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìä QUANTITATIVE RESULTS SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if len(df) > 0:\n",
    "    # Format and display the DataFrame\n",
    "    display_df = df[[\"Dataset\", \"GradCAM Score\", \"DiET Score\", \"Improvement\", \"DiET Better\"]].copy()\n",
    "    display_df[\"GradCAM Score\"] = display_df[\"GradCAM Score\"].apply(lambda x: f\"{x:.4f}\" if pd.notnull(x) else \"N/A\")\n",
    "    display_df[\"DiET Score\"] = display_df[\"DiET Score\"].apply(lambda x: f\"{x:.4f}\" if pd.notnull(x) else \"N/A\")\n",
    "    display_df[\"Improvement\"] = display_df[\"Improvement\"].apply(lambda x: f\"{x:+.4f}\" if pd.notnull(x) else \"N/A\")\n",
    "    display_df[\"DiET Better\"] = display_df[\"DiET Better\"].apply(lambda x: \"‚úÖ Yes\" if x else \"‚ùå No\")\n",
    "    \n",
    "    print(display_df.to_string(index=False))\n",
    "    \n",
    "    # Summary statistics\n",
    "    diet_wins = (df[\"DiET Better\"] == True).sum()\n",
    "    total = len(df)\n",
    "    avg_improvement = df[\"Improvement\"].mean()\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 70)\n",
    "    print(f\"üìà DiET outperforms GradCAM on {diet_wins}/{total} datasets\")\n",
    "    print(f\"üìä Average improvement: {avg_improvement:+.4f}\")\n",
    "else:\n",
    "    print(\"No results available. Please run the experiment first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Visualization: Method Comparison Across Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison visualizations\n",
    "if len(df) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Bar chart: GradCAM vs DiET scores\n",
    "    datasets = df[\"Dataset\"].tolist()\n",
    "    gradcam_scores = df[\"GradCAM Score\"].tolist()\n",
    "    diet_scores = df[\"DiET Score\"].tolist()\n",
    "    \n",
    "    x = np.arange(len(datasets))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = axes[0].bar(x - width/2, gradcam_scores, width, label='GradCAM', color='#2196F3', alpha=0.8)\n",
    "    bars2 = axes[0].bar(x + width/2, diet_scores, width, label='DiET', color='#4CAF50', alpha=0.8)\n",
    "    \n",
    "    axes[0].set_ylabel('Pixel Perturbation Score', fontsize=12)\n",
    "    axes[0].set_title('Attribution Quality Comparison\\n(Higher = Better)', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xticks(x)\n",
    "    axes[0].set_xticklabels(datasets, rotation=45, ha='right')\n",
    "    axes[0].legend(loc='upper right')\n",
    "    axes[0].set_ylim(0, 1)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars1 + bars2:\n",
    "        height = bar.get_height()\n",
    "        axes[0].annotate(f'{height:.2f}',\n",
    "                        xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                        xytext=(0, 3),\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # Improvement chart\n",
    "    improvements = df[\"Improvement\"].tolist()\n",
    "    colors = ['#4CAF50' if imp > 0 else '#F44336' for imp in improvements]\n",
    "    \n",
    "    axes[1].barh(datasets, improvements, color=colors, alpha=0.8)\n",
    "    axes[1].axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    axes[1].set_xlabel('Improvement (DiET - GradCAM)', fontsize=12)\n",
    "    axes[1].set_title('DiET Improvement Over GradCAM\\n(Positive = DiET Better)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    for i, v in enumerate(improvements):\n",
    "        axes[1].text(v + 0.01 if v >= 0 else v - 0.01, i, f'{v:+.3f}', \n",
    "                    va='center', ha='left' if v >= 0 else 'right', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./outputs/colab_experiments/image_comparison/method_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüìÅ Figure saved to: outputs/colab_experiments/image_comparison/method_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Visualization: Attribution Heatmaps\n",
    "\n",
    "Comparing GradCAM and DiET attributions on sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and display comparison visualizations\n",
    "try:\n",
    "    viz_files = comparison.visualize_results(save_plots=True, show=True)\n",
    "    print(\"\\nüìä Generated visualization files:\")\n",
    "    for name, path in viz_files.items():\n",
    "        print(f\"   ‚Ä¢ {name}: {path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Visualization generation skipped: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display saved heatmap comparisons if available\n",
    "import glob\n",
    "from IPython.display import Image, display\n",
    "\n",
    "viz_paths = glob.glob('./outputs/colab_experiments/image_comparison/**/diet_vs_gradcam.png', recursive=True)\n",
    "if viz_paths:\n",
    "    print(\"\\nüñºÔ∏è  Attribution Heatmap Comparisons:\")\n",
    "    for path in viz_paths[:2]:  # Show first 2 datasets\n",
    "        dataset_name = path.split('/')[-3]\n",
    "        print(f\"\\n--- {dataset_name.upper()} ---\")\n",
    "        display(Image(filename=path, width=800))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform statistical analysis\n",
    "if len(df) > 0:\n",
    "    from scipy import stats\n",
    "    \n",
    "    gradcam_scores = df[\"GradCAM Score\"].values\n",
    "    diet_scores = df[\"DiET Score\"].values\n",
    "    \n",
    "    # Paired t-test (if enough samples)\n",
    "    if len(gradcam_scores) >= 3:\n",
    "        t_stat, p_value = stats.ttest_rel(diet_scores, gradcam_scores)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"üìä STATISTICAL ANALYSIS\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"\\n  Paired t-test (DiET vs GradCAM):\")\n",
    "        print(f\"    t-statistic: {t_stat:.4f}\")\n",
    "        print(f\"    p-value: {p_value:.4f}\")\n",
    "        \n",
    "        if p_value < 0.05:\n",
    "            print(f\"\\n  ‚úÖ Result is statistically significant (p < 0.05)\")\n",
    "            if t_stat > 0:\n",
    "                print(f\"     ‚Üí DiET significantly outperforms GradCAM\")\n",
    "            else:\n",
    "                print(f\"     ‚Üí GradCAM significantly outperforms DiET\")\n",
    "        else:\n",
    "            print(f\"\\n  ‚ö†Ô∏è  Result is not statistically significant (p = {p_value:.4f})\")\n",
    "            print(f\"     ‚Üí No significant difference between methods\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  Not enough datasets for statistical testing (need ‚â• 3)\")\n",
    "    \n",
    "    # Effect size (Cohen's d)\n",
    "    if len(gradcam_scores) >= 2:\n",
    "        pooled_std = np.sqrt((np.var(gradcam_scores) + np.var(diet_scores)) / 2)\n",
    "        cohens_d = (np.mean(diet_scores) - np.mean(gradcam_scores)) / pooled_std if pooled_std > 0 else 0\n",
    "        \n",
    "        print(f\"\\n  Effect Size (Cohen's d): {cohens_d:.4f}\")\n",
    "        if abs(cohens_d) < 0.2:\n",
    "            print(\"     ‚Üí Small effect\")\n",
    "        elif abs(cohens_d) < 0.8:\n",
    "            print(\"     ‚Üí Medium effect\")\n",
    "        else:\n",
    "            print(\"     ‚Üí Large effect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Discussion and Conclusions\n",
    "\n",
    "### 5.1 Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary report\n",
    "if len(df) > 0:\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"üìã EXPERIMENT SUMMARY REPORT\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    diet_wins = (df[\"DiET Better\"] == True).sum()\n",
    "    total = len(df)\n",
    "    avg_gradcam = df[\"GradCAM Score\"].mean()\n",
    "    avg_diet = df[\"DiET Score\"].mean()\n",
    "    avg_improvement = df[\"Improvement\"].mean()\n",
    "    \n",
    "    print(f\"\\nüìä OVERALL PERFORMANCE:\")\n",
    "    print(f\"   ‚Ä¢ DiET wins: {diet_wins}/{total} datasets ({100*diet_wins/total:.1f}%)\")\n",
    "    print(f\"   ‚Ä¢ Average GradCAM Score: {avg_gradcam:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Average DiET Score: {avg_diet:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Average Improvement: {avg_improvement:+.4f}\")\n",
    "    \n",
    "    print(f\"\\nüîç KEY OBSERVATIONS:\")\n",
    "    if avg_improvement > 0:\n",
    "        print(f\"   1. DiET produces more discriminative attributions than GradCAM overall\")\n",
    "        print(f\"   2. The improvement is consistent across {diet_wins} of {total} tested datasets\")\n",
    "    else:\n",
    "        print(f\"   1. GradCAM shows competitive or better performance in this experiment\")\n",
    "        print(f\"   2. Consider running with more samples or epochs for definitive results\")\n",
    "    \n",
    "    print(f\"\\nüìà PER-DATASET BREAKDOWN:\")\n",
    "    for _, row in df.iterrows():\n",
    "        status = \"‚úÖ\" if row[\"DiET Better\"] else \"‚ùå\"\n",
    "        print(f\"   {status} {row['Dataset']}: GradCAM={row['GradCAM Score']:.4f}, DiET={row['DiET Score']:.4f} ({row['Improvement']:+.4f})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Limitations and Future Work\n",
    "\n",
    "**Limitations:**\n",
    "- Limited training epochs due to computational constraints\n",
    "- Fixed DiET hyperparameters may not be optimal for all datasets\n",
    "- Evaluation limited to pixel perturbation metric\n",
    "\n",
    "**Future Work:**\n",
    "- Extend to larger datasets (ImageNet)\n",
    "- Compare with other XAI methods (SHAP, LIME, Attention)\n",
    "- Investigate DiET hyperparameter sensitivity\n",
    "- Human evaluation of attribution quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Save Results and Export Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all results\n",
    "import json\n",
    "\n",
    "# Create comprehensive results dictionary\n",
    "full_results = {\n",
    "    \"experiment\": \"DiET vs GradCAM Image Comparison\",\n",
    "    \"date\": datetime.now().isoformat(),\n",
    "    \"configuration\": CONFIG,\n",
    "    \"device\": DEVICE,\n",
    "    \"gpu_config\": GPU_CONFIG,\n",
    "    \"results\": results,\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "results_path = \"./outputs/colab_experiments/image_comparison/full_results.json\"\n",
    "os.makedirs(os.path.dirname(results_path), exist_ok=True)\n",
    "\n",
    "def make_serializable(obj):\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, (np.float32, np.float64)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, (np.int32, np.int64)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: make_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [make_serializable(item) for item in obj]\n",
    "    return obj\n",
    "\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(make_serializable(full_results), f, indent=2)\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "if len(df) > 0:\n",
    "    df.to_csv('./outputs/colab_experiments/image_comparison/results_summary.csv', index=False)\n",
    "\n",
    "print(\"\\n‚úÖ Results saved successfully!\")\n",
    "print(f\"   üìÑ JSON: {results_path}\")\n",
    "print(f\"   üìä CSV: ./outputs/colab_experiments/image_comparison/results_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download results (for Colab)\n",
    "try:\n",
    "    from google.colab import files\n",
    "    \n",
    "    # Create zip of all results\n",
    "    !zip -r image_comparison_results.zip ./outputs/colab_experiments/image_comparison/\n",
    "    \n",
    "    print(\"\\nüì• Download your results:\")\n",
    "    files.download('image_comparison_results.zip')\n",
    "except:\n",
    "    print(\"\\nüìÅ Results are saved locally in: ./outputs/colab_experiments/image_comparison/\")\n",
    "    print(\"   (Download option only available in Google Colab)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö References\n",
    "\n",
    "1. Bhalla, U., et al. (2023). \"Discriminative Feature Attributions: Bridging Post Hoc Explainability and Inherent Interpretability.\" *NeurIPS 2023.*\n",
    "\n",
    "2. Selvaraju, R. R., et al. (2017). \"Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization.\" *ICCV 2017.*\n",
    "\n",
    "3. Krizhevsky, A. (2009). \"Learning Multiple Layers of Features from Tiny Images.\" *Technical Report, University of Toronto.*\n",
    "\n",
    "---\n",
    "\n",
    "**Notebook Version:** 1.0  \n",
    "**Last Updated:** 2025-2026 Academic Year  \n",
    "**Repository:** [github.com/xMOROx/Machine-Learning-Project-2025-2026](https://github.com/xMOROx/Machine-Learning-Project-2025-2026)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
