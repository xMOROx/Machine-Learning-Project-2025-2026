{
  "config": {
    "device": "cuda",
    "batch_size": 16,
    "cnn_batch_size": 32,
    "glue_batch_size": 8,
    "num_workers": 2,
    "cnn_epochs": 5,
    "glue_epochs": 2,
    "sample_size": 5000,
    "ig_steps": 20,
    "gradcam_samples": 8
  },
  "experiments": {
    "diet_comparison": {
      "timestamp": "2025-12-13T08:10:03.381641",
      "config": {
        "device": "cuda",
        "data_dir": "/home/patryk/programming/Machine-Learning-Project-2025-2026/data",
        "output_dir": "/home/patryk/programming/Machine-Learning-Project-2025-2026/outputs/xai_experiments/diet_comparison",
        "batch_size": 32,
        "max_samples_image": 5000,
        "max_samples_text": 2500,
        "epochs_image": 3,
        "epochs_text": 2,
        "comparison_samples": 8,
        "comparison_samples_text": 10
      },
      "image_experiments": {
        "baseline_accuracy": 88.51,
        "diet_accuracy": 87.64,
        "gradcam_perturbation": {
          "10": 0.375,
          "20": 0.375,
          "50": 0.375
        },
        "diet_perturbation": {
          "10": 0.25,
          "20": 0.375,
          "50": 0.875
        },
        "gradcam_mean_score": 0.375,
        "diet_mean_score": 0.5,
        "improvement": 0.125,
        "diet_better": true
      },
      "text_experiments": {
        "baseline_accuracy": 89.0,
        "ig_diet_overlap": 0.19333333333333333,
        "samples_compared": 10
      },
      "summary": {
        "report": "======================================================================\nXAI METHODS COMPARISON REPORT\n======================================================================\n\nGenerated: 2025-12-13T08:10:03.381641\nDevice: cuda\n\n--------------------------------------------------\nIMAGE CLASSIFICATION (CIFAR-10)\n--------------------------------------------------\n\nModel Accuracy:\n  Baseline: 88.51%\n  After DiET: 87.64%\n\nPixel Perturbation Results:\n  GradCAM Mean Score: 0.3750\n  DiET Mean Score: 0.5000\n\n  \u2713 DiET IMPROVES attribution by 0.1250\n  \u2192 DiET masks focus more on discriminative features\n\n--------------------------------------------------\nTEXT CLASSIFICATION (SST-2)\n--------------------------------------------------\n\nModel Accuracy:\n  BERT Baseline: 89.00%\n\nToken Attribution Comparison:\n  IG-DiET Top-k Overlap: 0.1933\n  Samples Compared: 10\n\n  \u2192 Methods identify different important tokens\n  \u2192 DiET may capture discriminative features IG misses\n\n======================================================================\nCONCLUSIONS\n======================================================================\n\n\u2022 For IMAGES: DiET provides more discriminative attributions\n  - Masks learned by DiET better preserve prediction-relevant features\n  - Recommended for applications requiring faithful explanations\n\n\u2022 For TEXT: DiET captures unique discriminative patterns\n  - Low overlap suggests DiET finds different important tokens\n  - May be valuable for sentiment-specific attributions\n\n======================================================================"
      },
      "total_time_seconds": 7488.501528978348
    }
  },
  "total_time_seconds": 7490.136734485626
}